# ğŸ§µ LabelSense

**Intelligent Defect Detection in Textile Labels**  
*Zeroâ€‘Shot YOLO Deployment with FastAPI & ONNX*

<p align="center">
  <img src="https://img.shields.io/badge/Model-YOLOv8-blue" />
  <img src="https://img.shields.io/badge/Server-FastAPI-green" />
  <img src="https://img.shields.io/badge/License-MIT-black" />
</p>

---

## ğŸŒ Overview

**LabelSense** is an AI solution that **automates qualityâ€‘control** by detecting defects in textile labelsâ€”printing errors, stains, structural flawsâ€”directly from productionâ€‘line images.  
Unlike classic approaches that require thousands of images per defect, LabelSense employs **zeroâ€‘shot detection**: the YOLO model can localise **a defect class it never saw during training**.

> This project was built for the **DataQuestÂ 2025** hackathon, where scoring is split 50â€‘50 between model accuracy and the interface / visualisation module.

---

## ğŸ¯ Key Features

- **Zeroâ€‘Shot YOLO** â€” detect unseen defect classes with textual prompts.
- **ONNX Runtime** â€” lightweight inference with GPU/CPU fallback.
- **FastAPI** â€” oneÂ `POSTÂ /predict`Â endpoint for image uploads.
- **CORS enabled** â€” plug into any webÂ / mobile frontend.
- **Plugâ€‘andâ€‘Play** â€” swap `DragNet.onnx` with any YOLOâ€‘family model.

---

## ğŸ–¼ï¸ Model Pipeline

```mermaid
graph TD
    A[Upload Image] --> B[Preâ€‘processing 640Ã—640]
    B --> C[YOLOv8 ONNX (Zeroâ€‘Shot)]
    C --> D[Postâ€‘processing]
    D --> E[JSON Response]
```

**Zeroâ€‘shot trick:** we attach a textual embedding (e.g. `"mis_print"`) to the detection head â€” no extra images required.

---

## âš™ï¸ Architecture

### 1Â Â· Preâ€‘processing

- Resize or letterbox to **640Â Ã—Â 640**.
- Convert grayscale âœÂ RGB if needed.
- Change layout **HWCÂ â†’Â CHW**, add batch dim.

### 2Â Â· Inference

- Load `DragNet.onnx` in **ONNXÂ Runtime**.
- Output: boundingâ€‘boxes, confidence, classâ€‘ids.
- Map zeroâ€‘shot classes via `names.json`.

### 3Â Â· FastAPI Service

```http
POST /predict
Contentâ€‘Type: multipart/formâ€‘data
file=<image>
â†’ { "prediction": [...] }
```

---

## ğŸš€ Quickstart

```bash
# 1Â Â· Clone + install deps
$ git clone https://github.com/your-org/LabelSense.git
$ cd LabelSense
$ pip install -r requirements.txt

# 2Â Â· Run locally
$ uvicorn app:app --reload --host 0.0.0.0 --port 8000

# 3Â Â· Test
$ curl -F "file=@examples/label.jpg" http://localhost:8000/predict
```

---

## ğŸ“Š Hackathon Scoring

| Criterion | Weight |
|-----------|-------:|
| **Model Accuracy**<br/>Precision Â· Recall Â· F1 Â· mAP | **89â€¯%** |


LabelSense fully covers the accuracy component and exposes a REST API so any frontend team can build the analytics dashboard.

---

## ğŸ¤ Contributing

1. Fork the project  
2. Create your feature branch: `git checkout -b feat/awesome`  
3. Commit changes: `git commit -m "feat: add awesome"`  
4. Push: `git push origin feat/awesome`  
5. Open a Pull Request

---

<p align="center"><strong>Made with â¤ï¸Â by the LabelSense Team Â· IEEEÂ INSAT DataQuestÂ 2025</strong></p>

